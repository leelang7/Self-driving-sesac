import time
import cv2
from ultralytics import YOLO
from flask import Flask, Response

app = Flask(__name__)

# =========================
# ì„¤ì •
# =========================

# ì›¹ìº  ì¸ë±ìŠ¤
WEBCAM_INDEX = 0

# RTSP ì£¼ì†Œ
#RTSP_URL = "rtsp://sesac1234:sesac1234@172.16.8.25/stream1"
RTSP_URL = "cam01.mp4"

# auto / webcam / rtsp
SOURCE_MODE = "rtsp"

# YOLO ëª¨ë¸ ë¡œë”©
MODEL_PATH = "yolo11n.pt"
print("[INFO] YOLO ëª¨ë¸ ë¡œë”© ì¤‘...")
model = YOLO(MODEL_PATH)
print("[INFO] YOLO ëª¨ë¸ ë¡œë”© ì™„ë£Œ")

# ì‚¬ëŒ í´ë˜ìŠ¤ ID (COCO ê¸°ì¤€ 0)
PERSON_CLASS_ID = 0


# =========================
#  ì›¹ìº  â†’ ì‹¤íŒ¨ â†’ RTSP ìë™ fallback
# =========================
def open_capture():
    if SOURCE_MODE == "webcam":
        print(f"[INFO] webcam only â†’ {WEBCAM_INDEX}")
        cap = cv2.VideoCapture(WEBCAM_INDEX)
        if cap.isOpened():
            print("[INFO] ì›¹ìº  ì—´ê¸° ì„±ê³µ")
            return cap, f"webcam:{WEBCAM_INDEX}"
        print("[ERROR] ì›¹ìº  ì—´ê¸° ì‹¤íŒ¨")
        return None, None

    if SOURCE_MODE == "rtsp":
        print(f"[INFO] rtsp only â†’ {RTSP_URL}")
        cap = cv2.VideoCapture(RTSP_URL)
        if cap.isOpened():
            print("[INFO] RTSP ì—´ê¸° ì„±ê³µ")
            return cap, RTSP_URL
        print("[ERROR] RTSP ì—´ê¸° ì‹¤íŒ¨")
        return None, None

    # auto ëª¨ë“œ
    print("[INFO] SOURCE_MODE=auto â†’ ì›¹ìº  ë¨¼ì € ì‹œë„")

    cap = cv2.VideoCapture(WEBCAM_INDEX)
    if cap.isOpened():
        print(f"[INFO] auto: ì›¹ìº  ì„±ê³µ â†’ {WEBCAM_INDEX}")
        return cap, f"webcam:{WEBCAM_INDEX}"

    print("[WARN] auto: ì›¹ìº  ì‹¤íŒ¨ â†’ RTSP ì‹œë„")

    cap = cv2.VideoCapture(RTSP_URL)
    if cap.isOpened():
        print(f"[INFO] auto: RTSP ì„±ê³µ â†’ {RTSP_URL}")
        return cap, RTSP_URL

    print("[FATAL] auto: ë‘˜ ë‹¤ ì‹¤íŒ¨")
    return None, None


# =========================
#  MJPEG Streaming + YOLO Tracking
# =========================
def generate():
    cap, source = open_capture()

    if cap is None:
        print("[ERROR] ì˜ìƒ ì†ŒìŠ¤ë¥¼ ì—´ì§€ ëª»í•¨")
        while True:
            # ë¹ˆ í”„ë ˆì„ ë°˜ë³µ ì†¡ì¶œ (UIëŠ” ê²€ì • í™”ë©´ ìœ ì§€)
            yield (
                b"--frame\r\nContent-Type: image/jpeg\r\n\r\n" + b"" + b"\r\n"
            )
            time.sleep(1)

    print(f"[INFO] ì‚¬ìš© ì¤‘ì¸ ì†ŒìŠ¤: {source}")

    fps_ema = 0.0

    while True:
        t0 = time.time()

        ret, frame = cap.read()
        if not ret:
            print("[WARN] í”„ë ˆì„ ì½ê¸° ì‹¤íŒ¨ â†’ ì¬ì‹œë„")
            time.sleep(0.05)
            continue

        # =========================
        # ì‚¬ëŒ(person)ë§Œ YOLO tracking
        # =========================
        results = model.track(
            frame,
            persist=True,
            classes=[PERSON_CLASS_ID],  # ğŸ”¥ ì‚¬ëŒë§Œ ì¶”ì 
            verbose=False
        )

        # bbox + id + mask + label ëª¨ë‘ ê·¸ë¦° ì´ë¯¸ì§€
        annotated = results[0].plot()

        # FPS
        t1 = time.time()
        inst_fps = 1.0 / max((t1 - t0), 1e-6)
        fps_ema = 0.9 * fps_ema + 0.1 * inst_fps

        cv2.putText(
            annotated,
            f"FPS: {fps_ema:.1f}",
            (10, 30),
            cv2.FONT_HERSHEY_SIMPLEX,
            1.0,
            (0, 255, 0),
            2,
            cv2.LINE_AA,
        )

        ok, jpeg = cv2.imencode(".jpg", annotated)
        if not ok:
            continue

        yield (
            b"--frame\r\n"
            b"Content-Type: image/jpeg\r\n\r\n" + jpeg.tobytes() + b"\r\n"
        )


@app.route("/video_feed")
def video_feed():
    return Response(
        generate(),
        mimetype="multipart/x-mixed-replace; boundary=frame"
    )


if __name__ == "__main__":
    app.run(host="0.0.0.0", port=5000, debug=False, threaded=True)
